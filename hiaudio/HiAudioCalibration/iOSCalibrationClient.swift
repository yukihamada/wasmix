// ğŸ“± HiAudio Pro - iPhone Calibration Client
// macOS CalibrationEngineã¨é€£æºã™ã‚‹iOSå´å®Ÿè£…

import Foundation
import AVFoundation
import Accelerate
import Network
import CoreML

// MARK: - Calibration Client Protocol
protocol CalibrationClientDelegate: AnyObject {
    func calibrationDidStart()
    func calibrationDidReceiveProgress(_ progress: Float, message: String)
    func calibrationDidComplete(result: CalibrationResult)
    func calibrationDidFail(error: CalibrationError)
}

// MARK: - Calibration Error Types
enum CalibrationError: Error, LocalizedError {
    case audioPermissionDenied
    case networkConnectionFailed
    case hardwareNotSupported
    case calibrationTimedOut
    case invalidAudioFormat
    case positioningError
    
    var errorDescription: String? {
        switch self {
        case .audioPermissionDenied:
            return "ãƒã‚¤ã‚¯ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒå¿…è¦ã§ã™"
        case .networkConnectionFailed:
            return "macOSã‚¢ãƒ—ãƒªã¨ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .hardwareNotSupported:
            return "ã“ã®æ©Ÿç¨®ã¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡å¤–ã§ã™"
        case .calibrationTimedOut:
            return "ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
        case .invalidAudioFormat:
            return "éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç„¡åŠ¹ã§ã™"
        case .positioningError:
            return "ãƒ‡ãƒã‚¤ã‚¹ã®ä½ç½®æ¸¬å®šã«å¤±æ•—ã—ã¾ã—ãŸ"
        }
    }
}

// MARK: - Main iOS Calibration Client
class iOSCalibrationClient: ObservableObject {
    
    // MARK: - Properties
    weak var delegate: CalibrationClientDelegate?
    
    @Published var connectionStatus: ConnectionStatus = .disconnected
    @Published var calibrationState: CalibrationState = .idle
    @Published var currentProgress: Float = 0.0
    @Published var statusMessage: String = "å¾…æ©Ÿä¸­"
    
    // Audio Engine
    private var audioEngine: AVAudioEngine?
    private var audioSession: AVAudioSession?
    private var inputNode: AVAudioInputNode?
    
    // Network
    private var connection: NWConnection?
    private var listener: NWListener?
    
    // Calibration Data
    private var deviceInfo: DeviceInfo?
    private var recordingBuffer: [Float] = []
    private var calibrationStartTime: Date?
    
    // Configuration
    private let sampleRate: Double = 48000.0
    private let bufferSize: AVAudioFrameCount = 1024
    private let maxRecordingDuration: TimeInterval = 10.0
    
    // MARK: - Connection Status
    enum ConnectionStatus {
        case disconnected
        case connecting
        case connected
        case error(String)
        
        var description: String {
            switch self {
            case .disconnected: return "æœªæ¥ç¶š"
            case .connecting: return "æ¥ç¶šä¸­..."
            case .connected: return "æ¥ç¶šæ¸ˆã¿"
            case .error(let message): return "ã‚¨ãƒ©ãƒ¼: \(message)"
            }
        }
    }
    
    // MARK: - Calibration State
    enum CalibrationState {
        case idle
        case preparing
        case listening
        case analyzing
        case completed
        case failed(CalibrationError)
        
        var description: String {
            switch self {
            case .idle: return "å¾…æ©Ÿä¸­"
            case .preparing: return "æº–å‚™ä¸­"
            case .listening: return "éŒ²éŸ³ä¸­"
            case .analyzing: return "è§£æä¸­"
            case .completed: return "å®Œäº†"
            case .failed(let error): return "å¤±æ•—: \(error.localizedDescription)"
            }
        }
    }
    
    // MARK: - Initialization
    init() {
        setupDeviceInfo()
        setupAudioSession()
    }
    
    deinit {
        disconnect()
        stopAudioEngine()
    }
    
    // MARK: - Device Information Setup
    private func setupDeviceInfo() {
        let modelName = UIDevice.current.model
        let systemVersion = UIDevice.current.systemVersion
        let deviceName = UIDevice.current.name
        
        // iPhoneæ©Ÿç¨®åˆ¤åˆ¥
        var modelIdentifier = "Unknown"
        var size = 0
        sysctlbyname("hw.machine", nil, &size, nil, 0)
        var machine = [CChar](repeating: 0, count: size)
        sysctlbyname("hw.machine", &machine, &size, nil, 0)
        modelIdentifier = String(cString: machine)
        
        deviceInfo = DeviceInfo(
            id: UIDevice.current.identifierForVendor?.uuidString ?? UUID().uuidString,
            name: deviceName,
            model: modelIdentifier,
            iOSVersion: systemVersion,
            microphoneType: getMicrophoneType(for: modelIdentifier),
            capabilities: getDeviceCapabilities(for: modelIdentifier)
        )
        
        print("ğŸ“± Device Info: \(deviceInfo?.description ?? "Unknown")")
    }
    
    private func getMicrophoneType(for modelIdentifier: String) -> String {
        // iPhoneæ©Ÿç¨®åˆ¥ã®ãƒã‚¤ã‚¯ã‚¿ã‚¤ãƒ—ã‚’è¿”ã™
        if modelIdentifier.contains("iPhone15") {
            return "Triple-mic array with spatial audio"
        } else if modelIdentifier.contains("iPhone14") || modelIdentifier.contains("iPhone13") {
            return "Dual-mic array with spatial audio"
        } else if modelIdentifier.contains("iPhone12") || modelIdentifier.contains("iPhone11") {
            return "Dual-mic array"
        } else {
            return "Standard microphone"
        }
    }
    
    private func getDeviceCapabilities(for modelIdentifier: String) -> DeviceCapabilities {
        // æ©Ÿç¨®åˆ¥ã®æ€§èƒ½æƒ…å ±
        let maxSampleRate: Double
        let channelCount: Int
        let hasAdvancedDSP: Bool
        
        if modelIdentifier.contains("iPhone15") || modelIdentifier.contains("iPhone14") {
            maxSampleRate = 48000.0
            channelCount = 2
            hasAdvancedDSP = true
        } else if modelIdentifier.contains("iPhone13") || modelIdentifier.contains("iPhone12") {
            maxSampleRate = 48000.0
            channelCount = 1
            hasAdvancedDSP = true
        } else {
            maxSampleRate = 44100.0
            channelCount = 1
            hasAdvancedDSP = false
        }
        
        return DeviceCapabilities(
            maxSampleRate: maxSampleRate,
            channelCount: channelCount,
            hasBuiltinCalibration: hasAdvancedDSP
        )
    }
    
    // MARK: - Audio Session Setup
    private func setupAudioSession() {
        audioSession = AVAudioSession.sharedInstance()
        
        do {
            try audioSession?.setCategory(.playAndRecord, 
                                        mode: .measurement,
                                        options: [.defaultToSpeaker, .allowBluetooth])
            try audioSession?.setActive(true)
            
            // æœ€é«˜å“è³ªè¨­å®š
            try audioSession?.setPreferredSampleRate(sampleRate)
            try audioSession?.setPreferredIOBufferDuration(Double(bufferSize) / sampleRate)
            
            print("âœ… Audio session configured: \(sampleRate)Hz, \(bufferSize) frames")
            
        } catch {
            print("âŒ Audio session setup failed: \(error)")
        }
    }
    
    // MARK: - Network Connection
    func connectToMacOS(host: String, port: UInt16 = 55556) {
        connectionStatus = .connecting
        statusMessage = "macOSã‚¢ãƒ—ãƒªã«æ¥ç¶šä¸­..."
        
        let hostEndpoint = NWEndpoint.Host(host)
        let portEndpoint = NWEndpoint.Port(integerLiteral: port)
        let endpoint = NWEndpoint.hostPort(host: hostEndpoint, port: portEndpoint)
        
        connection = NWConnection(to: endpoint, using: .udp)
        
        connection?.stateUpdateHandler = { [weak self] state in
            DispatchQueue.main.async {
                switch state {
                case .ready:
                    self?.connectionStatus = .connected
                    self?.statusMessage = "æ¥ç¶šå®Œäº†"
                    self?.sendDeviceRegistration()
                    
                case .failed(let error):
                    self?.connectionStatus = .error(error.localizedDescription)
                    self?.statusMessage = "æ¥ç¶šå¤±æ•—"
                    
                case .cancelled:
                    self?.connectionStatus = .disconnected
                    self?.statusMessage = "æ¥ç¶šçµ‚äº†"
                    
                default:
                    break
                }
            }
        }
        
        connection?.start(queue: .global())
    }
    
    func disconnect() {
        connection?.cancel()
        connection = nil
        connectionStatus = .disconnected
        statusMessage = "åˆ‡æ–­æ¸ˆã¿"
    }
    
    // MARK: - Device Registration
    private func sendDeviceRegistration() {
        guard let deviceInfo = deviceInfo,
              let connection = connection else { return }
        
        let registrationData = CalibrationMessage.deviceRegistration(deviceInfo)
        
        do {
            let data = try JSONEncoder().encode(registrationData)
            connection.send(content: data, completion: .contentProcessed({ error in
                if let error = error {
                    print("âŒ Device registration failed: \(error)")
                } else {
                    print("âœ… Device registered successfully")
                }
            }))
        } catch {
            print("âŒ Registration encoding failed: \(error)")
        }
    }
    
    // MARK: - Calibration Process
    func startCalibration() async throws {
        guard connectionStatus == .connected else {
            throw CalibrationError.networkConnectionFailed
        }
        
        // 1. æ¨©é™ç¢ºèª
        let permission = await requestMicrophonePermission()
        guard permission else {
            throw CalibrationError.audioPermissionDenied
        }
        
        // 2. éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™
        try setupAudioEngine()
        
        // 3. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹é€šçŸ¥
        calibrationState = .preparing
        delegate?.calibrationDidStart()
        calibrationStartTime = Date()
        
        // 4. macOSã«é–‹å§‹é€šçŸ¥
        sendCalibrationReady()
        
        // 5. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¿¡å·å¾…æ©Ÿ
        try await waitForCalibrationSignal()
    }
    
    private func requestMicrophonePermission() async -> Bool {
        return await withCheckedContinuation { continuation in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
    }
    
    private func setupAudioEngine() throws {
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            throw CalibrationError.hardwareNotSupported
        }
        
        inputNode = audioEngine.inputNode
        
        let format = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                   sampleRate: sampleRate,
                                   channels: 1,
                                   interleaved: false)!
        
        // é«˜ç²¾åº¦éŒ²éŸ³è¨­å®š
        inputNode?.installTap(onBus: 0,
                             bufferSize: bufferSize,
                             format: format) { [weak self] buffer, time in
            self?.processAudioBuffer(buffer, time: time)
        }
        
        try audioEngine.start()
        print("âœ… Audio engine started for calibration")
    }
    
    private func stopAudioEngine() {
        audioEngine?.stop()
        inputNode?.removeTap(onBus: 0)
        audioEngine = nil
        inputNode = nil
    }
    
    // MARK: - Audio Processing
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, time: AVAudioTime) {
        guard calibrationState == .listening,
              let channelData = buffer.floatChannelData?[0] else { return }
        
        let frameCount = Int(buffer.frameLength)
        let audioData = Array(UnsafeBufferPointer(start: channelData, count: frameCount))
        
        // ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        recordingBuffer.append(contentsOf: audioData)
        
        // é€²æ—æ›´æ–°
        let currentDuration = Double(recordingBuffer.count) / sampleRate
        let progress = Float(currentDuration / maxRecordingDuration)
        
        DispatchQueue.main.async { [weak self] in
            self?.currentProgress = min(progress, 1.0)
            self?.statusMessage = "éŒ²éŸ³ä¸­... \(String(format: "%.1f", currentDuration))ç§’"
            self?.delegate?.calibrationDidReceiveProgress(progress, message: self?.statusMessage ?? "")
        }
        
        // æœ€å¤§éŒ²éŸ³æ™‚é–“ã«é”ã—ãŸå ´åˆ
        if currentDuration >= maxRecordingDuration {
            completeRecording()
        }
    }
    
    private func completeRecording() {
        calibrationState = .analyzing
        stopAudioEngine()
        
        DispatchQueue.main.async { [weak self] in
            self?.statusMessage = "éŒ²éŸ³å®Œäº† - è§£æä¸­..."
        }
        
        // macOSã«éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿é€ä¿¡
        sendRecordingData()
    }
    
    // MARK: - Network Communication
    private func sendCalibrationReady() {
        let message = CalibrationMessage.calibrationReady(
            deviceId: deviceInfo?.id ?? "",
            timestamp: Date().timeIntervalSince1970
        )
        sendMessage(message)
    }
    
    private func sendRecordingData() {
        guard !recordingBuffer.isEmpty else { return }
        
        let message = CalibrationMessage.audioData(
            deviceId: deviceInfo?.id ?? "",
            sampleRate: sampleRate,
            data: recordingBuffer,
            timestamp: Date().timeIntervalSince1970
        )
        
        sendMessage(message)
        
        // ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
        recordingBuffer.removeAll()
    }
    
    private func sendMessage(_ message: CalibrationMessage) {
        guard let connection = connection else { return }
        
        do {
            let data = try JSONEncoder().encode(message)
            connection.send(content: data, completion: .contentProcessed({ error in
                if let error = error {
                    print("âŒ Message send failed: \(error)")
                }
            }))
        } catch {
            print("âŒ Message encoding failed: \(error)")
        }
    }
    
    private func waitForCalibrationSignal() async throws {
        // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡å¾…æ©Ÿ
        guard let connection = connection else {
            throw CalibrationError.networkConnectionFailed
        }
        
        try await withCheckedThrowingContinuation { continuation in
            receiveMessages(continuation: continuation)
        }
    }
    
    private func receiveMessages(continuation: CheckedContinuation<Void, Error>?) {
        connection?.receive(minimumIncompleteLength: 1, maximumLength: 65536) { [weak self] data, _, isComplete, error in
            
            if let error = error {
                continuation?.resume(throwing: CalibrationError.networkConnectionFailed)
                return
            }
            
            if let data = data {
                self?.processReceivedMessage(data)
            }
            
            if !isComplete {
                self?.receiveMessages(continuation: continuation)
            }
        }
    }
    
    private func processReceivedMessage(_ data: Data) {
        do {
            let message = try JSONDecoder().decode(CalibrationMessage.self, from: data)
            
            switch message {
            case .startCalibration:
                DispatchQueue.main.async { [weak self] in
                    self?.calibrationState = .listening
                    self?.statusMessage = "ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¿¡å·ã‚’éŒ²éŸ³ä¸­..."
                }
                
            case .calibrationResult(let result):
                DispatchQueue.main.async { [weak self] in
                    self?.calibrationState = .completed
                    self?.statusMessage = "ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†"
                    self?.currentProgress = 1.0
                    self?.delegate?.calibrationDidComplete(result: result)
                }
                
            case .calibrationError(let errorMessage):
                DispatchQueue.main.async { [weak self] in
                    let error = CalibrationError.calibrationTimedOut // ã¾ãŸã¯é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
                    self?.calibrationState = .failed(error)
                    self?.statusMessage = "ã‚¨ãƒ©ãƒ¼: \(errorMessage)"
                    self?.delegate?.calibrationDidFail(error: error)
                }
                
            default:
                break
            }
            
        } catch {
            print("âŒ Message decoding failed: \(error)")
        }
    }
}

// MARK: - Supporting Data Structures

struct DeviceInfo: Codable {
    let id: String
    let name: String
    let model: String
    let iOSVersion: String
    let microphoneType: String
    let capabilities: DeviceCapabilities
    
    var description: String {
        return "\(model) (\(name)) - \(microphoneType)"
    }
}

enum CalibrationMessage: Codable {
    case deviceRegistration(DeviceInfo)
    case calibrationReady(deviceId: String, timestamp: TimeInterval)
    case startCalibration
    case audioData(deviceId: String, sampleRate: Double, data: [Float], timestamp: TimeInterval)
    case calibrationResult(CalibrationResult)
    case calibrationError(String)
}

// MARK: - Extensions for Integration

extension iOSCalibrationClient {
    
    /// ç°¡æ˜“ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰)
    func performQuickCalibration() async throws {
        try await startCalibration()
        
        // è‡ªå‹•é€²è¡Œã‚’ãƒ¢ãƒ‹ã‚¿ãƒ¼
        while calibrationState != .completed && calibrationState != .failed(CalibrationError.calibrationTimedOut) {
            try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’å¾…æ©Ÿ
        }
        
        if case .failed(let error) = calibrationState {
            throw error
        }
    }
    
    /// ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆ
    func resetCalibration() {
        calibrationState = .idle
        currentProgress = 0.0
        statusMessage = "å¾…æ©Ÿä¸­"
        recordingBuffer.removeAll()
        stopAudioEngine()
    }
    
    /// ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã®æ›´æ–°
    func updateDeviceInfo() {
        setupDeviceInfo()
    }
}

// MARK: - Audio Quality Extensions

extension iOSCalibrationClient {
    
    /// éŸ³å£°å“è³ªã®äº‹å‰ãƒã‚§ãƒƒã‚¯
    func checkAudioQuality() async -> AudioQualityReport {
        let report = AudioQualityReport()
        
        // ãƒã‚¤ã‚¯å‹•ä½œç¢ºèª
        do {
            try setupAudioEngine()
            
            // çŸ­æ™‚é–“éŒ²éŸ³ãƒ†ã‚¹ãƒˆ
            let testDuration: TimeInterval = 1.0
            var testBuffer: [Float] = []
            
            // ç°¡æ˜“éŒ²éŸ³ãƒ†ã‚¹ãƒˆ (å®Ÿè£…çœç•¥)
            
            stopAudioEngine()
            
            report.microphoneStatus = .working
            report.backgroundNoiseLevel = calculateNoiseLevel(testBuffer)
            report.recommendedSettings = getRecommendedSettings()
            
        } catch {
            report.microphoneStatus = .error(error.localizedDescription)
        }
        
        return report
    }
    
    private func calculateNoiseLevel(_ buffer: [Float]) -> Float {
        guard !buffer.isEmpty else { return 0 }
        
        let rms = sqrt(buffer.map { $0 * $0 }.reduce(0, +) / Float(buffer.count))
        return 20 * log10(rms + 1e-6) // dB
    }
    
    private func getRecommendedSettings() -> [String: Any] {
        return [
            "sampleRate": sampleRate,
            "bufferSize": bufferSize,
            "optimalDistance": "30cm - 1m",
            "environment": "é™ã‹ãªå®¤å†…ã‚’æ¨å¥¨",
            "orientation": "ç”»é¢ã‚’ä¸Šå‘ãã«"
        ]
    }
}

struct AudioQualityReport {
    enum MicrophoneStatus {
        case working
        case warning(String)
        case error(String)
    }
    
    var microphoneStatus: MicrophoneStatus = .working
    var backgroundNoiseLevel: Float = 0.0 // dB
    var recommendedSettings: [String: Any] = [:]
    
    var isGoodQuality: Bool {
        switch microphoneStatus {
        case .working:
            return backgroundNoiseLevel > -40.0 // -40dBä»¥ä¸‹ã®ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢
        case .warning, .error:
            return false
        }
    }
}